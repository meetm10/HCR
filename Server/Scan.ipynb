{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from __future__ import print_function\n",
    "from pyimagesearch.transform import four_point_transform\n",
    "from pyimagesearch import imutils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Manual Contours List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual Contours\n",
    "man_contours = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Click function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click(event,x,y,flags,param):\n",
    "\n",
    "\tglobal image,man_contours\n",
    "\n",
    "\tif event == cv2.EVENT_LBUTTONDOWN:\n",
    "\t\tprint(\"******You pressed -->({0},{1})\".format(x,y))\n",
    "\t\tman_contours.append([x,y])\n",
    "\n",
    "\t\t#Found 4 contours..\n",
    "\t\tif len(man_contours)==4:\n",
    "\t\t\tprint(\"*****Found 4 Contours :\",man_contours)\n",
    "\t\t\t\n",
    "\treturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually pick contours for Edge Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_contours():\n",
    "\tglobal image,man_contours\n",
    "\n",
    "\tprint(\"\\n\\n*********Manually Finding Contours, click on 4 corners to select a Region***********\")\n",
    "\n",
    "\t#Create a window and setMouseCallback\n",
    "\tcv2.namedWindow(\"Original_Image\",cv2.WINDOW_NORMAL)\n",
    "\tcv2.setMouseCallback(\"Original_Image\",on_click)\n",
    "\n",
    "\t# keep looping until the 'q' key is pressed\n",
    "\twhile True:\n",
    "\t\t# display the image and wait for a keypress\n",
    "\t\tcv2.imshow(\"Original_Image\", image)\n",
    "\t\tkey = cv2.waitKey(1) & 0xFF\n",
    "\t\tif key == ord('q'):\n",
    "\t\t\tbreak\n",
    "\n",
    "\tprint(\"****Finished Finding Contours******\")\n",
    "\n",
    "\treturn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ScreenCountours..\n",
    "screenCnt = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-i\", \"--image\", required = True,\n",
    "#     help = \"Path to the image to be scanned\")\n",
    "# args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the image and compute the ratio of the old height to the new height, clone it, and resize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Images/try.jpg')\n",
    "if image is None:\n",
    "    print(\"******Failed to load Image*******\")\n",
    "    exit(0)\n",
    "\n",
    "ratio = image.shape[0] / 500.0\n",
    "orig = image.copy()\n",
    "image = imutils.resize(image, height = 500)\n",
    "outline = image.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the image to grayscale, blur it, and find edges in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Edge Detection\n"
     ]
    }
   ],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(gray, 75, 200)\n",
    "\n",
    "# show the original image and the edge detected image\n",
    "print(\"STEP 1: Edge Detection\")\n",
    "cv2.namedWindow(\"Image\",cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.namedWindow(\"Edged\",cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.imwrite(\"Edged.jpg\",edged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the contours in the edged image, keeping only the largest ones, and initialize the screen contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:15]\n",
    "\n",
    "#Flag for automatic edge detection..\n",
    "auto = False\n",
    "\n",
    "# loop over the contours\n",
    "for c in cnts:\n",
    "    # approximate the contour\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "\n",
    "    # if our approximated contour has four points, then we\n",
    "    # can assume that we have found our screen\n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        auto = True\n",
    "        break\n",
    "\n",
    "#If 4 contours not found..\n",
    "if auto:\n",
    "    # show the contour (outline) of the piece of paper\n",
    "    print(\"STEP 2: Find contours of paper\")\n",
    "    cv2.namedWindow(\"Outline\",cv2.WINDOW_NORMAL)\n",
    "    cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 4)\n",
    "    cv2.imshow(\"Outline\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Is the Output Satisfactory? \\nDo you want to pick Contours Manully? Y/N : \", end=\"\")\n",
    "    response = input()\n",
    "    if response.upper()==\"Y\":\n",
    "        #Reset the image\n",
    "        image = outline\n",
    "        pick_contours()\n",
    "        screenCnt = np.array(man_contours)\n",
    "        cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "        cv2.namedWindow(\"Outline\",cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"Outline\", image)\n",
    "        cv2.imwrite(\"Outline.jpg\",image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "else:\n",
    "    print(\"******Automatic Edge Detection Failed*******\")\n",
    "    pick_contours()\n",
    "    screenCnt = np.array(man_contours)\n",
    "    cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "    cv2.namedWindow(\"Outline\",cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"Outline\", image)\n",
    "    cv2.imwrite(\"Outline.jpg\",image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the four point transform to obtain a top-down view of the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped = four_point_transform(orig, screenCnt.reshape(4, 2)*ratio)\n",
    "\n",
    "cv2.imwrite(\"Corrected Perspective.jpg\",warped)\n",
    "\n",
    "# convert the warped image to grayscale, then threshold it to give it that 'black and white' paper effect\n",
    "\n",
    "gray_warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "# cv2.imshow(\"GrayScale\",gray_warped)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "gray_warped_blur = cv2.medianBlur(gray_warped,5)\n",
    "# cv2.imshow(\"Blurred\",gray_warped_blur)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# thresholdValue = threshold_otsu(gray_blur, 256)\n",
    "# ret3,warped = cv2.threshold(gray_blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "binarized = cv2.adaptiveThreshold(gray_warped_blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                                    cv2.THRESH_BINARY,3,2)\n",
    "\n",
    "# show the original and scanned images\n",
    "print(\"STEP 3: Apply perspective transform\")\n",
    "cv2.imwrite(\"Original.jpg\",orig)\n",
    "cv2.namedWindow(\"Scanned\",cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"Scanned\",width=500,height = 500)\n",
    "cv2.imshow(\"Scanned\", binarized)\n",
    "cv2.imwrite(\"Binarized.jpg\",binarized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
